# GEx Predictor

**GEx Predictor** is a tool for predicting gene expression based on chemical molecules represented as SMILES. It uses a trained neural network to generate predictions from **global molecular signatures** produced with `Signaturizer`.  


# Features

- Standardization of SMILES using RDKit.  
- Generation of global molecular signatures (GLOBAL Signature) with `Signaturizer`.  
- Gene expression prediction using a deep learning model (`GenomicExpressionNet2`).  
- Compatible with GPU and CPU via PyTorch.  

# Data and Model Training

The predictive model in **GEx Predictor** has been trained using data from the **LINCS (Library of Integrated Network-based Cellular Signatures)** project, which provides large-scale gene expression profiles in response to chemical perturbations.

To enrich the dataset and cover molecules not directly available in LINCS, we leveraged the **Chemical Checker (CC)** resource developed by the Structural Bioinformatics and Network Biology (SBNB) group at IRB Barcelona. The workflow was as follows:

1. **LINCS data**: Experimental gene expression signatures were used as the foundation (~20,000 molecules).  
2. **Chemical Checker molecules**: Additional molecules from the CC were included to expand the chemical space.  
3. **KNN imputation**: For molecules in the Chemical Checker that are **close to LINCS compounds in signature space**, we applied *k-nearest neighbors (KNN) imputation* to estimate their gene expression profiles.  

As a result, the final training dataset combines:  
- **~20,000 experimental LINCS profiles**, and  
- **~80,000 imputed gene expression profiles** for chemically similar molecules (from the CC).  

In total, the dataset contains approximately **100,000 molecules**.  

## Model Training Strategy

- To ensure robust evaluation and avoid overfitting to specific chemotypes, we used a **scaffold split**: molecules were partitioned based on their chemical scaffolds rather than random sampling.  
- The model was trained and validated using **5-fold cross-validation**, where each fold uses a different subset of scaffolds for testing and the remaining scaffolds for training/validation.  
- This strategy guarantees that the model is tested on **novel scaffolds** not seen during training, providing a more realistic estimate of generalization performance.


# GLOBAL Molecular Signature

This project uses the **GLOBAL molecular signature** generated by `Signaturizer`. This signature represents the chemical and bioactive properties of a molecule in a comprehensive way, as a 3,200-dimensional vector.

## Key details
- GLOBAL signatures combine multiple bioactivity spaces, capturing a complete representation of the molecule.  
- Each signature is a high-dimensional vector summarizing chemical and biological information.  
- Signatures are generated via Siamese neural networks trained with a triplet approach (anchor, positive, negative), allowing bioactively similar molecules to have close representations in vector space.  
- These representations are useful for predicting biological properties, comparing compounds, and analyzing chemical similarity.  

## Workflow in the predictor
1. The molecule is standardized (clean-up, largest fragment, uncharging, tautomerization).  
2. The **GLOBAL signature** of the molecule is generated.  
3. The signature is converted to a tensor and fed into the trained neural network to obtain gene expression predictions.  


# Installation

1. Clone the repository:  
```bash
git clone https://github.com/AdriaVico/GEx_Predictor.git
cd GEx_Predictor
```


# Usage
from predictor import GEx_Predictor

# Initialize the predictor
predictor = GEx_Predictor()

# Prediction from SMILES
smiles = "CCO"
prediction = predictor.predict(smiles, input_type="SMILES")

print(prediction)

# Project Structure
GEx_Predictor/
├─ model/
│ └─ fold_4.pt # Trained model
├─ predictor.py # GEx_Predictor class
├─ requirements.txt # Dependencies
└─ README.md

# Requirements

- Python >= 3.8
- PyTorch
- RDKit
- Signaturizer

# Contributing

Contributions are welcome for improving molecule standardization, model optimization, and adding new prediction features.